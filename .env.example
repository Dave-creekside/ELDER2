# ELDER Mind Configuration Template
# Copy this file to .env and fill in your settings

# LLM Provider Configuration
# Choose your LLM provider: anthropic, openai, gemini, groq, ollama, or lmstudio
LLM_PROVIDER=ollama

# Anthropic Configuration (if using anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4000

# OpenAI Configuration (if using openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Google Gemini Configuration (if using gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# Groq Configuration (if using groq)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=mixtral-8x7b-32768

# Ollama Configuration (for local LLM)
OLLAMA_MODEL=llama3.2:latest
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TEMPERATURE=0.7

# LM Studio Configuration (OpenAI-compatible local API)
# LM Studio provides better tool handling than Ollama for many models
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=local-model  # Will auto-detect loaded model if set to 'local-model'
LMSTUDIO_API_KEY=  # Usually not required for LM Studio
LMSTUDIO_TEMPERATURE=0.7
LMSTUDIO_MAX_TOKENS=4000
# Dream-specific settings for higher creativity
LMSTUDIO_DREAM_TEMPERATURE=0.9
LMSTUDIO_DREAM_MAX_TOKENS=8000

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=

# Sentence Transformers Configuration
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2

# System Configuration
LOG_LEVEL=INFO
SHOW_HAUSDORFF_IN_RESPONSE=true
DEFAULT_DREAM_ITERATIONS=3
ENABLE_HAUSDORFF_MONITORING=true

# Debugging Configuration
DISABLE_CA=false
